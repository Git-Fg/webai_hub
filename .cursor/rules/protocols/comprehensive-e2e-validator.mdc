---
description: A modular, high-level directive for validating system integrity by testing each provider individually, with an optional workflow for multi-provider orchestration.

alwaysApply: false

---

# Modular System Integrity Protocol

## YOUR MISSION: Achieve Production Readiness

Your mission is to ensure the AI Hybrid Hub is robust and functional by validating each provider integration individually. If explicitly requested, you will also validate the multi-provider orchestration workflow.

You are to operate with complete autonomy and unwavering persistence. Any bug or failed test is simply the next problem to be solved in the debug-and-remediate cycle.

## Input Parameters

- **`testMultiProvider: boolean`** (default: `false`):

  - If `false` or not provided, you MUST execute the **Default Workflow**.

  - If `true`, you MUST execute the **Optional Workflow**.

---

### Default Workflow: Individual Provider Validation

This is the standard, default workflow. Your goal is to iterate through all supported providers and run a full, isolated validation on each one to guarantee its individual functionality.

#### Your Mandate & Methodology

1.  **Discover Providers:** You MUST read `packages/bridge/chatbots/index.ts` to identify all keys (provider IDs) in the `SUPPORTED_SITES` export. This is your definitive list of providers to test.

2.  **Iterate and Validate:** For each discovered provider ID, you MUST execute the `@protocols/autonomous-validator` protocol. This protocol will handle the entire lifecycle of testing that single provider, including setting up a session, running tests, and autonomously fixing any bugs found.

3.  **Persistence:** You MUST attempt to validate every discovered provider. If a fix for one provider fails, document it as a "Persistent Failure" as per the `autonomous-validator` protocol and proceed to the next provider.

---

### Optional Workflow: Multi-Provider Orchestration (`testMultiProvider: true`)

This workflow is executed **only when `testMultiProvider` is explicitly set to `true`**. Your goal is to verify that the app's key value proposition—orchestrating a single prompt across multiple providers—is fully functional.

#### Your Mandate & Methodology

1.  **Test Plan:**

    a. Select at least two different, functional providers from the UI.

    b. Send a single, shared prompt.

    c. Analyze the session log to verify that the automation cycles for both providers complete and that their responses appear correctly aggregated in the Hub's curation panel.

2.  **Remediation:** If the orchestration fails at any step (e.g., failure to switch tabs, incorrect prompt delivery, missing responses in the curation panel), you MUST enter the `@core/pattern-debug-loop` to diagnose and fix the issue.

---

### Core Toolset (Applies to Both Workflows)

-   **Environment & Perception:** Use `@core/pattern-session-management` for clean test environments and rely on the session log as your primary source of truth.

-   **Problem Solving:** The `@core/pattern-debug-loop` is your fundamental strategy for addressing any failure.

-   **Selector Ground Truth:** The files within the `validation/` directory are your primary reference for known-good CSS selectors.

---

### Definition of Done

Your mission is complete only when:

-   The selected workflow (either individual validation for all providers or multi-provider orchestration) operates flawlessly.

-   All temporary diagnostic code has been removed.

-   All necessary fixes have been committed to the local repository, adhering to `@core/protocol-version-control`.
